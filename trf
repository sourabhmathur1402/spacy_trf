import pandas as pd
import spacy
import random
import re
from spacy.training import Example
from spacy.util import minibatch, compounding

# Load and clean data
file_path = 'final_train_data.csv'  # Adjust with the actual path of your CSV file
df = pd.read_csv(file_path)

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\W', ' ', text)
    text = text.strip().lower()
    return text

df['Text'] = df['Text'].apply(clean_text)

TRAIN_DATA = []
for index, row in df.iterrows():
    text = row['Text']
    entities = []
    for label in ['OUTBOUND_DESTINATION', 'OUTBOUND_COUNTRY_DESTINATION', 'OUTBOUND_TRAVEL_DATE',
                  'INBOUND_TRAVEL_DATE', 'OUTBOUND_SOURCE', 'OUTBOUND_COUNTRY_SOURCE',
                  'SENDER_EMAIL', 'TRAVELER_EMAIL', 'INBOUND_SOURCE']:
        start_index = text.find(str(row[label]).lower())
        if start_index != -1:
            end_index = start_index + len(str(row[label]))
            # Check if the new entity overlaps with existing entities
            new_entity = (start_index, end_index, label.upper())
            if not any(start_idx < end_index and end_idx > start_index for start_idx, end_idx, _ in entities):
                entities.append(new_entity)
    
    TRAIN_DATA.append((text, {"entities": entities}))

# Model class
class Model(object):

    def __init__(self, modelName="testmodel"):
        self.nlp = spacy.blank("en")
        self.modelName = modelName

    def train(self, output_dir=None, n_iter=80):
        if "ner" not in self.nlp.pipe_names:
            ner = self.nlp.add_pipe("ner")
        else:
            ner = self.nlp.get_pipe("ner")

        # Adding labels to the NER pipe
        for _, annotations in TRAIN_DATA:
            for ent in annotations.get("entities"):
                ner.add_label(ent[2])

        # Disable existing transformers component
        if "transformer" in self.nlp.pipe_names:
            self.nlp.remove_pipe("transformer")

        # Add transformer embeddings
        trf = self.nlp.add_pipe("transformer", name="trf", last=True)
        trf.model.initialize()

        # Disabling other pipes for training only NER
        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner" and pipe != "trf"]
        with self.nlp.disable_pipes(*other_pipes):
            self.nlp.begin_training()

            for itn in range(n_iter):
                print("Iteration : {} ".format(itn))
                random.shuffle(TRAIN_DATA)

                losses = {}
                batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))

                for batch in batches:
                    examples = []
                    for text, annotations in batch:
                        doc = self.nlp.make_doc(text)
                        example = Example.from_dict(doc, annotations)
                        examples.append(example)

                    self.nlp.update(
                        examples,
                        drop=0.5,
                        losses=losses,
                    )
                print("Losses", losses)

            if output_dir is not None:
                self.nlp.to_disk(output_dir)
                print(f'Model has been trained and saved to {output_dir}')

# Creating a Model instance and training it
model = Model()
model.train(output_dir='ab', n_iter=20)  # Adjust the number of iterations and output directory as needed
